{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"auto_encoding\"\n",
        "date: \"2023-10-06\"\n",
        "categories: [code]\n",
        "format: html\n",
        "---"
      ],
      "id": "d59ecd6b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchinfo import summary\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "id": "362bfac9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_root = './data'\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5),\n",
        "    transforms.Lambda(lambda x: x.view(-1)),\n",
        "])\n",
        "\n",
        "trainset = datasets.MNIST(\n",
        "    root        = data_root, \n",
        "    train       = True, \n",
        "    download    = True,\n",
        "    transform   = transform\n",
        ")\n",
        "\n",
        "testset = datasets.MNIST(\n",
        "    root        = data_root, \n",
        "    train       = False, \n",
        "    download    = False,\n",
        "    transform   = transform\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = trainset,\n",
        "    batch_size  = batch_size,\n",
        "    shuffle     = True\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = testset,\n",
        "    batch_size  = batch_size,\n",
        "    shuffle     = False\n",
        ")"
      ],
      "id": "879968a7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "parser = argparse.ArgumentParser(description='parser for argparse test')\n",
        "\n",
        "parser.add_argument('--input_dim', type=int, default=28*28)\n",
        "parser.add_argument('--learning_rate', type=float, default=0.001)\n",
        "parser.add_argument('--num_epoch', type=int, default=10)\n",
        "parser.add_argument('--enc_hidden_dim', type=str, default='256,128,64,32,3')\n",
        "parser.add_argument('--dec_hidden_dim', type=str, default='32,64,128,256')\n",
        "\n",
        "\n",
        "if 'ipykernel_launcher' in sys.argv[0]:\n",
        "    sys.argv = [sys.argv[0]]\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "enc_hidden_dim = args.enc_hidden_dim.split(',')\n",
        "dec_hidden_dim = args.dec_hidden_dim.split(',')\n",
        "args.enc_hidden_dim_list = []\n",
        "args.dec_hidden_dim_list = []\n",
        "\n",
        "args.enc_hidden_dim_list.append(args.input_dim)\n",
        "\n",
        "for i in enc_hidden_dim:\n",
        "    args.enc_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.enc_hidden_dim_list\n",
        "\n",
        "args.dec_hidden_dim_list.append(args.enc_hidden_dim_list[-1])\n",
        "\n",
        "for i in dec_hidden_dim:\n",
        "    args.dec_hidden_dim_list.append(int(i))\n",
        "\n",
        "args.dec_hidden_dim_list.append(args.input_dim)\n",
        "\n",
        "args.dec_hidden_dim_list\n",
        "\n",
        "args"
      ],
      "id": "3800f1d2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "class midlayer(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(midlayer, self).__init__()\n",
        "        self.fc_layer = nn.Linear(input_dim, hidden_dim)\n",
        "        self.activation = nn.LeakyReLU()\n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "        out = self.activation(out)\n",
        "        return out\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        layer_list = []\n",
        "        for i in range(len(hidden_dim_list)-1):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "        \n",
        "        self.fc_layer = nn.Sequential(*layer_list)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_dim_list):\n",
        "        super().__init__()\n",
        "        \n",
        "        layer_list = []\n",
        "        for i in range(len(hidden_dim_list)-2):\n",
        "            layer_list.append(midlayer(hidden_dim_list[i], hidden_dim_list[i+1]))\n",
        "        \n",
        "        layer_list.append(nn.Sequential(nn.Linear(hidden_dim_list[i+1], hidden_dim_list[i+2]), nn.Sigmoid()))\n",
        "        self.fc_layer = nn.Sequential(*layer_list)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc_layer(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, enc_hidden_dim_list, dec_hidden_dim_list):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = Encoder(enc_hidden_dim_list)\n",
        "        self.decoder = Decoder(dec_hidden_dim_list)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.encoder(x)\n",
        "        out = self.decoder(out)\n",
        "\n",
        "        return out"
      ],
      "id": "ef5df382",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "autoencoder = Autoencoder(args.enc_hidden_dim_list, args.dec_hidden_dim_list)\n",
        "autoencoder = autoencoder.to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)"
      ],
      "id": "8447afb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def train_autoencoder(autoencoder, criterion, optimizer, num_epochs):\n",
        "    train_loss_arr = []\n",
        "    test_loss_arr = []\n",
        "\n",
        "    best_test_loss = 99999999\n",
        "    early_stop, early_stop_max = 0., 3.\n",
        "    for epoch in range(num_epochs):\n",
        "        autoencoder.train()\n",
        "        epoch_loss = 0.\n",
        "        for data in train_loader:\n",
        "            inputs, _ = data\n",
        "            inputs = inputs.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = autoencoder(inputs.view(inputs.size(0), -1))\n",
        "            train_loss = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
        "            epoch_loss += train_loss.data\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_loss_arr.append(epoch_loss / len(train_loader.dataset))\n",
        "        \n",
        "        if epoch != 99:\n",
        "            autoencoder.eval()\n",
        "\n",
        "            test_loss = 0.\n",
        "\n",
        "            for data in test_loader:\n",
        "                inputs, _ = data\n",
        "                inputs = inputs.to(device)\n",
        "\n",
        "                outputs = autoencoder(inputs.view(inputs.size(0), -1))\n",
        "                batch_loss = criterion(outputs, inputs.view(inputs.size(0), -1))\n",
        "                test_loss += batch_loss.data\n",
        "\n",
        "            test_loss = test_loss\n",
        "            test_loss_arr.append(test_loss)\n",
        "\n",
        "            if best_test_loss > test_loss:\n",
        "                best_test_loss = test_loss\n",
        "                early_stop = 0\n",
        "\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f} *')\n",
        "            else:\n",
        "                early_stop += 1\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss.item():.4f}, Test Loss: {batch_loss.item():.4f}') \n",
        "\n",
        "        if early_stop >= early_stop_max:\n",
        "            break\n",
        "\n",
        "def visualize_images(original, reconstructed, n=10):\n",
        "    plt.figure(figsize=(20, 4))\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(original[i].reshape(28, 28), cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()"
      ],
      "id": "bd23c3a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "train_autoencoder(autoencoder, criterion, optimizer, num_epochs=args.num_epoch)\n",
        "\n",
        "data_iter = iter(test_loader)\n",
        "images, _ = next(data_iter)\n",
        "reconstructed = autoencoder(images)\n",
        "visualize_images(images, reconstructed.detach().numpy())"
      ],
      "id": "307ebd8a",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}